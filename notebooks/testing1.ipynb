{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a pyspark instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "team = \"team17\"\n",
    "\n",
    "warehouse = \"project/hive/warehouse\"\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "        .appName(\"{} - spark ML\".format(team))\\\n",
    "        .master(\"yarn\")\\\n",
    "        .config(\"hive.metastore.uris\", \"thrift://hadoop-02.uni.innopolis.ru:9883\")\\\n",
    "        .config(\"spark.sql.warehouse.dir\", warehouse)\\\n",
    "        .config(\"spark.executor.instances\", 4)\\\n",
    "        .config(\"spark.sql.avro.compression.codec\", \"snappy\")\\\n",
    "        .enableHiveSupport()\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = spark.read.format(\"avro\").table('team17_projectdb.weather_conditions_updated')\n",
    "air_quality = spark.read.format(\"avro\").table('team17_projectdb.air_quality_region')\n",
    "location_and_time = spark.read.format(\"avro\").table('team17_projectdb.location_and_time_region')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing last_updated from time to year, month, day, hour, minute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year, month, dayofmonth, hour, minute\n",
    "\n",
    "location_and_time = location_and_time.select(\n",
    "    \"*\",\n",
    "    year(\"last_updated\").alias(\"year\"),\n",
    "    month(\"last_updated\").alias(\"month\"),\n",
    "    dayofmonth(\"last_updated\").alias(\"day\"),\n",
    "    hour(\"last_updated\").alias(\"hour\"),\n",
    "    minute(\"last_updated\").alias(\"minute\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_and_time.select('month').first()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- location_id: integer (nullable = true)\n",
      " |-- temperature_celsius: string (nullable = true)\n",
      " |-- temperature_fahrenheit: string (nullable = true)\n",
      " |-- wind_mph: string (nullable = true)\n",
      " |-- wind_kph: string (nullable = true)\n",
      " |-- wind_degree: integer (nullable = true)\n",
      " |-- wind_direction: string (nullable = true)\n",
      " |-- pressure_mb: string (nullable = true)\n",
      " |-- pressure_in: string (nullable = true)\n",
      " |-- precip_mm: string (nullable = true)\n",
      " |-- precip_in: string (nullable = true)\n",
      " |-- humidity: integer (nullable = true)\n",
      " |-- cloud: integer (nullable = true)\n",
      " |-- feels_like_celsius: string (nullable = true)\n",
      " |-- feels_like_fahrenheit: string (nullable = true)\n",
      " |-- visibility_km: string (nullable = true)\n",
      " |-- visibility_miles: string (nullable = true)\n",
      " |-- uv_index: string (nullable = true)\n",
      " |-- gust_mph: string (nullable = true)\n",
      " |-- gust_kph: string (nullable = true)\n",
      " |-- sunrise: string (nullable = true)\n",
      " |-- sunset: string (nullable = true)\n",
      " |-- moonrise: string (nullable = true)\n",
      " |-- moonset: string (nullable = true)\n",
      " |-- moon_phase: string (nullable = true)\n",
      " |-- moon_illumination: integer (nullable = true)\n",
      " |-- condition_text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting time features into sin/cos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from pyspark.ml import Transformer\n",
    "from pyspark.ml.param import Param, Params\n",
    "from pyspark.sql.functions import sin, cos, col\n",
    "\n",
    "class SinCosEncoder(Transformer, Params):\n",
    "    inputCol = Param(Params._dummy(), \"inputCol\", \"input column name\")\n",
    "    outputCols = Param(Params._dummy(), \"outputCols\", \"output column names\")\n",
    "\n",
    "    def __init__(self, inputCol, outputCols):\n",
    "        super(SinCosEncoder, self).__init__()\n",
    "        self._setDefault(inputCol=inputCol, outputCols=outputCols)\n",
    "\n",
    "    def getInputCol(self):\n",
    "        return self.getOrDefault(self.inputCol)\n",
    "    \n",
    "    def getOutputCols(self):\n",
    "        return self.getOrDefault(self.outputCols)\n",
    "\n",
    "    def _transform(self, df):\n",
    "        input_col = self.getInputCol()\n",
    "        output_cols = self.getOutputCols()\n",
    "        sin_col = f\"{output_cols[0]}\"\n",
    "        cos_col = f\"{output_cols[1]}\"\n",
    "\n",
    "        df = df.withColumn(sin_col, sin(2 * math.pi * col(input_col) / 12))\n",
    "        df = df.withColumn(cos_col, cos(2 * math.pi * col(input_col) / 12))\n",
    "        return df\n",
    "\n",
    "class MonthEncoder(SinCosEncoder):\n",
    "    def __init__(self, inputCol=\"month\", outputCols=[\"monthsin\", \"monthcos\"]):\n",
    "        super().__init__(inputCol, outputCols)\n",
    "\n",
    "class DayEncoder(SinCosEncoder):\n",
    "    def __init__(self, inputCol=\"day\", outputCols=[\"daysin\", \"daycos\"]):\n",
    "        super().__init__(inputCol, outputCols)\n",
    "\n",
    "class HourEncoder(SinCosEncoder):\n",
    "    def __init__(self, inputCol=\"hour\", outputCols=[\"hoursin\", \"hourcos\"]):\n",
    "        super().__init__(inputCol, outputCols)\n",
    "\n",
    "class MinuteEncoder(SinCosEncoder):\n",
    "    def __init__(self, inputCol=\"minute\", outputCols=[\"minutesin\", \"minutecos\"]):\n",
    "        super().__init__(inputCol, outputCols)\n",
    "\n",
    "class SecondEncoder(SinCosEncoder):\n",
    "    def __init__(self, inputCol=\"second\", outputCols=[\"secondsins\", \"secondcos\"]):\n",
    "        super().__init__(inputCol, outputCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, to_timestamp, expr\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler, StringIndexer, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = weather.withColumn(\"temperature_celsius\", col(\"temperature_celsius\").cast(\"double\")) \\\n",
    "                 .withColumn(\"temperature_fahrenheit\", col(\"temperature_fahrenheit\").cast(\"double\"))\\\n",
    "                 .withColumn(\"wind_mph\", col(\"wind_mph\").cast(\"double\"))\\\n",
    "                 .withColumn(\"wind_kph\", col(\"wind_kph\").cast(\"double\"))\\\n",
    "                 .withColumn(\"pressure_mb\", col(\"pressure_mb\").cast(\"double\"))\\\n",
    "                 .withColumn(\"pressure_in\", col(\"pressure_in\").cast(\"double\"))\\\n",
    "                 .withColumn(\"precip_mm\", col(\"precip_mm\").cast(\"double\"))\\\n",
    "                 .withColumn(\"precip_in\", col(\"precip_in\").cast(\"double\"))\\\n",
    "                 .withColumn(\"feels_like_celsius\", col(\"feels_like_celsius\").cast(\"double\"))\\\n",
    "                 .withColumn(\"feels_like_fahrenheit\", col(\"feels_like_fahrenheit\").cast(\"double\"))\\\n",
    "                 .withColumn(\"visibility_km\", col(\"visibility_km\").cast(\"double\"))\\\n",
    "                 .withColumn(\"visibility_miles\", col(\"visibility_miles\").cast(\"double\"))\\\n",
    "                 .withColumn(\"uv_index\", col(\"uv_index\").cast(\"double\"))\\\n",
    "                 .withColumn(\"gust_kph\", col(\"gust_kph\").cast(\"double\"))\\\n",
    "                 .withColumn(\"gust_mph\", col(\"gust_mph\").cast(\"double\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_encoder = MonthEncoder()\n",
    "day_encoder = DayEncoder()\n",
    "hour_encoder = HourEncoder()\n",
    "minute_encoder = MinuteEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting coordinates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Transformer\n",
    "from pyspark.ml.util import DefaultParamsReadable, DefaultParamsWritable\n",
    "import numpy as np\n",
    "\n",
    "class LatLonToECEF(Transformer, DefaultParamsReadable, DefaultParamsWritable):\n",
    "    def _transform(self, df):\n",
    "        # Earth's radius in kilometers approx 6371\n",
    "        R = 6371\n",
    "        df = df.withColumn(\"x\", R * cos(col(\"latitude\") * np.pi / 180) * cos(col(\"longitude\") * np.pi / 180))\n",
    "        df = df.withColumn(\"y\", R * cos(col(\"latitude\") * np.pi / 180) * sin(col(\"longitude\") * np.pi / 180))\n",
    "        df = df.withColumn(\"z\", R * sin(col(\"latitude\") * np.pi / 180))\n",
    "        return df\n",
    "\n",
    "ecef_encoder = LatLonToECEF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = weather.join(air_quality, on=\"location_id\", how=\"inner\")\n",
    "data = data.join(location_and_time, on=\"location_id\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We dropped temperature_fahrenheit, wind_mph, pressure_in, precip_in, feels_like_fahreheit, visibility_miles, gust_mph\n",
    "# Because we already have the same features, just in metric format (kph instead of mph, celsius instead of fahrenheit, mm instead of in, and so on)\n",
    "# also, wind degree and wind direction are redundant features\n",
    "# city and region is not needed as we have latitude and longitude\n",
    "# sun and moon features have no effect on the air quality because they are external factors, but moon_illumination has an effect\n",
    "feature_cols = [\"x\", \"y\", \"z\",   # ECEF coordinates\n",
    "                \"monthsin\", \"monthcos\", \"daysin\", \"daycos\", \"hoursin\", \"hourcos\", \"minutesin\", \"minutecos\",   # time encodings\n",
    "                \"temperature_celsius\", \"humidity\", \"wind_kph\", \"pressure_mb\", \"precip_mm\", \"cloud\", \"feels_like_celsius\", \"visibility_km\", \"uv_index\", \"gust_kph\", \"wind_degree\", \"moon_illumination\"]\n",
    "\n",
    "# Convert text categories to indices\n",
    "condition_indexer = StringIndexer(inputCol=\"condition_text\", outputCol=\"condition_index\")\n",
    "# Convert indices to one-hot encoded variables\n",
    "condition_encoder = OneHotEncoder(inputCols=[\"condition_index\"], outputCols=[\"condition_encoded\"])\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_cols + [\"condition_encoded\"], outputCol=\"features\")\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n",
    "\n",
    "# Select one or more air quality measures as labels depending on your analysis approach\n",
    "label_col = \"air_quality_us_epa_index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[month_encoder, day_encoder, hour_encoder, minute_encoder,\n",
    "                            ecef_encoder, condition_indexer, condition_encoder, assembler, scaler])\n",
    "model = pipeline.fit(data)\n",
    "transformed_data = model.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(40, {0: 3.2733, 1: 24.4164, 2: 1.7444, 3: -0.6303, 4: 2.0372, 5: 0.7181, 6: -1.2306, 7: -1.477, 8: 0.7048, 10: 1.3824, 11: 5.148, 12: 3.8574, 13: 3.6236, 14: 186.9008, 16: 2.2142, 17: 4.7664, 18: 2.9182, 19: 1.2396, 20: 2.8293, 21: 3.1601, 22: 2.782, 24: 2.2565})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_data.select(\"scaled_features\").first()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = transformed_data.randomSplit([0.7, 0.3], seed=42)\n",
    "train_data.write.mode('overwrite').json(\"project/data/train\")\n",
    "test_data.write.mode('overwrite').json(\"project/data/test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting model 1: RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Define the model\n",
    "rf_base = RandomForestRegressor(featuresCol='scaled_features', labelCol=label_col)\n",
    "\n",
    "# Setup evaluation metric\n",
    "rf_evaluator = RegressionEvaluator(labelCol=label_col, predictionCol=\"prediction\")\n",
    "\n",
    "# Fit the model\n",
    "rf_base_model = rf_base.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R^2:  0.5370130382709225\n",
      "Test RMSE:  0.9953526130379097\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on the test set\n",
    "predictions = rf_base_model.transform(test_data)\n",
    "\n",
    "# Evaluate the best model and print out the result\n",
    "rf_base_r2 = rf_evaluator.evaluate(predictions, {rf_evaluator.metricName: \"r2\"})\n",
    "rf_base_rmse = rf_evaluator.evaluate(predictions, {rf_evaluator.metricName: \"rmse\"})\n",
    "print(\"Test R^2: \", rf_base_r2)\n",
    "print(\"Test RMSE: \", rf_base_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add just the model, then do gridsearch on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Define the model\n",
    "rf_tuned = RandomForestRegressor(featuresCol='scaled_features', labelCol=label_col)\n",
    "\n",
    "# Define the grid of hyperparameters to test:\n",
    "#  - numTrees: number of trees in the forest.\n",
    "#  - maxDepth: maximum depth of each tree.\n",
    "rf_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf_tuned.numTrees, [20, 30]) \\\n",
    "    .addGrid(rf_tuned.maxDepth, [5, 10]) \\\n",
    "    .build()\n",
    "\n",
    "# Setup evaluation metric\n",
    "rf_tuned_evaluator = RegressionEvaluator(labelCol=label_col, predictionCol=\"prediction\")\n",
    "\n",
    "# Cross-validator\n",
    "rf_cv = CrossValidator(estimator=rf_tuned,\n",
    "                    estimatorParamMaps=rf_paramGrid,\n",
    "                    evaluator=rf_tuned_evaluator,\n",
    "                    numFolds=3)\n",
    "\n",
    "# Fit the model\n",
    "rf_cvModel = rf_cv.fit(train_data)\n",
    "\n",
    "# Choose the best model\n",
    "rf_bestModel = rf_cvModel.bestModel\n",
    "\n",
    "# Save the best model\n",
    "rf_bestModel.write().overwrite().save(\"project/models/model1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxDepth: 10\n",
      "numTrees: 30\n"
     ]
    }
   ],
   "source": [
    "bestParams = rf_bestModel.extractParamMap()\n",
    "for param, value in bestParams.items():\n",
    "    if param.name == \"numTrees\" or param.name == \"maxDepth\":\n",
    "      print(f\"{param.name}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R^2:  0.7138348870917375\n",
      "Test RMSE:  0.7825298696415471\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on the test set\n",
    "rf_tuned_predictions = rf_bestModel.transform(test_data)\n",
    "rf_tuned_predictions.select(label_col, \"prediction\").coalesce(1).write.mode('overwrite').option(\"header\", \"true\").csv(\"project/output/model1_predictions.csv\")\n",
    "\n",
    "# Evaluate the best model and print out the result\n",
    "rf_tuned_r2 = rf_tuned_evaluator.evaluate(rf_tuned_predictions, {rf_tuned_evaluator.metricName: \"r2\"})\n",
    "rf_tuned_rmse = rf_tuned_evaluator.evaluate(rf_tuned_predictions, {rf_tuned_evaluator.metricName: \"rmse\"})\n",
    "print(\"Test R^2: \", rf_tuned_r2)\n",
    "print(\"Test RMSE: \", rf_tuned_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add just the model, then do gridsearch on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "# Initialize the GBTRegressor\n",
    "gbt_base = GBTRegressor(featuresCol='scaled_features', labelCol=label_col)\n",
    "\n",
    "gbt_evaluator = RegressionEvaluator(labelCol=label_col, predictionCol=\"prediction\")\n",
    "\n",
    "# Fit the model\n",
    "gbt_base_model = gbt_base.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R^2:  0.6554341181228047\n",
      "Test RMSE:  0.858674798100258\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on the test set\n",
    "gbt_base_predictions = gbt_base_model.transform(test_data)\n",
    "\n",
    "# Evaluate the best model and print out the result\n",
    "gbt_base_r2 = gbt_evaluator.evaluate(gbt_base_predictions, {gbt_evaluator.metricName: \"r2\"})\n",
    "gbt_base_rmse = gbt_evaluator.evaluate(gbt_base_predictions, {gbt_evaluator.metricName: \"rmse\"})\n",
    "print(\"Test R^2: \", gbt_base_r2)\n",
    "print(\"Test RMSE: \", gbt_base_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "# Initialize the GBTRegressor\n",
    "gbt_tuned = GBTRegressor(featuresCol='scaled_features', labelCol=label_col)\n",
    "\n",
    "gbt_tuned_evaluator = RegressionEvaluator(labelCol=label_col, predictionCol=\"prediction\")\n",
    "\n",
    "# Define the parameter grid for tuning\n",
    "gbt_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(gbt_tuned.maxDepth, [5, 10]) \\\n",
    "    .addGrid(gbt_tuned.maxIter, [20, 30]) \\\n",
    "    .build()\n",
    "\n",
    "# Setup CrossValidator for model tuning\n",
    "gbt_crossval = CrossValidator(estimator=gbt_tuned,\n",
    "                          estimatorParamMaps=gbt_paramGrid,\n",
    "                          evaluator=gbt_tuned_evaluator,\n",
    "                          numFolds=3)  # Use 3+ folds in practice\n",
    "\n",
    "# Fit the model\n",
    "gbt_cvModel = gbt_crossval.fit(train_data)\n",
    "\n",
    "gbt_bestModel = gbt_cvModel.bestModel\n",
    "gbt_bestModel.write().overwrite().save(\"project/models/model2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxDepth: 10\n",
      "maxIter: 30\n"
     ]
    }
   ],
   "source": [
    "gbt_bestParams = gbt_bestModel.extractParamMap()\n",
    "for param, value in gbt_bestParams.items():\n",
    "    if param.name == \"maxIter\" or param.name == \"maxDepth\":\n",
    "      print(f\"{param.name}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R^2:  0.7693112052121618\n",
      "Test RMSE:  0.7025962548893449\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on the test set\n",
    "gbt_tuned_predictions = gbt_bestModel.transform(test_data)\n",
    "gbt_tuned_predictions.select(label_col, \"prediction\").coalesce(1).write.mode('overwrite').option(\"header\", \"true\").csv(\"project/output/model2_predictions.csv\")\n",
    "\n",
    "# Evaluate the best model and print out the result\n",
    "gbt_tuned_r2 = gbt_tuned_evaluator.evaluate(gbt_tuned_predictions, {gbt_tuned_evaluator.metricName: \"r2\"})\n",
    "gbt_tuned_rmse = gbt_tuned_evaluator.evaluate(gbt_tuned_predictions, {gbt_tuned_evaluator.metricName: \"rmse\"})\n",
    "print(\"Test R^2: \", gbt_tuned_r2)\n",
    "print(\"Test RMSE: \", gbt_tuned_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a comparison dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+------------------+\n",
      "|          model_name|         r2_metric|       rmse_metric|\n",
      "+--------------------+------------------+------------------+\n",
      "|RandomForestRegre...|0.7138348870917375|0.7825298696415471|\n",
      "|        GBTRegressor|0.7693112052121618|0.7025962548893449|\n",
      "+--------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "evaluation_data = [\n",
    "    Row(model_name=\"RandomForestRegressor\", r2_metric=rf_tuned_r2, rmse_metric=rf_tuned_rmse),\n",
    "    Row(model_name=\"GBTRegressor\", r2_metric=gbt_tuned_r2, rmse_metric=gbt_tuned_rmse)\n",
    "]\n",
    "evaluation_df = spark.createDataFrame(evaluation_data)\n",
    "\n",
    "# Show DataFrame contents\n",
    "evaluation_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_df.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv('output/evaluation/evaluation.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
